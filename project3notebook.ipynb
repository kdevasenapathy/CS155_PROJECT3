{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS155 Project 3: Shakespearean Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from HMM_Project3 import unsupervised_HMM\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "\n",
    "#### Initial Attempt:\n",
    "- Process the words line by line\n",
    "- Remove line containing numbering for poem (1, 2, 3, etc.)\n",
    "- Change all the words to lowercase\n",
    "- Uses TweetTokenizer to separate words (retains apostrophes and hyphens)\n",
    "- Remove all punctualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_init(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is poem numbering\n",
    "        if sentence != [] and not sentence[0].isnumeric():\n",
    "            obs_elem = []\n",
    "            punct = \".',':;!?()\"; \n",
    "            \n",
    "            for word in sentence:\n",
    "                # Remove intermediate punctuation\n",
    "                if not word in punct:\n",
    "                    # Turn to lowercase\n",
    "                    word = word.lower()\n",
    "                    if word not in obs_map:\n",
    "                        # Add unique words to the observations map.\n",
    "                        obs_map[word] = obs_counter\n",
    "                        obs_counter += 1\n",
    "\n",
    "                    # Add the encoded word.\n",
    "                    obs_elem.append(obs_map[word])\n",
    "\n",
    "            # Add the encoded sequence.\n",
    "            obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map = preprocess_init(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning and Poetry Generation with HMMs:\n",
    "\n",
    "If we were to do a training/testing split for using validation to determine the number of states, we wouldn't be able to guarantee that every state would end up in the training set since some words only appear once in all of the poems. So, we will instead generate some sample poems and subjectively judge the best number of states, as suggested on Piazza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Attempt:\n",
    "- Determine number of words in each line by sampling randomly from all of the line lengths\n",
    "- Dictate all of the end-line punctuation to be commas except for the final line, which ends with a period.\n",
    "- Use characteristic 14-phrase structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of all shakespeare line lengths (in terms of number of words)\n",
    "line_lens = [len(i) for i in obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_init(hmm, obs_map, line_lens):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    for i in range(14):\n",
    "        # Get desired line length:\n",
    "        n_words = random.choice(line_lens)\n",
    "        emission, states = hmm.generate_emission(n_words)\n",
    "        sentence = [obs_map_r[i] for i in emission]\n",
    "        \n",
    "        formatted = ' '.join(sentence).capitalize()\n",
    "        if i < 13:\n",
    "            formatted += \",\\n\"\n",
    "        else:\n",
    "            formatted += \".\"\n",
    "        \n",
    "        poem += formatted\n",
    "\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate poems for 1, 2, 4, 8, and 16 hidden states to assess coherency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Of climbed so same shop and they place from,\n",
      "Walls of each what my her state be,\n",
      "Dear me posterity within in ) love's thy,\n",
      "Poet white verse thy the gone dote my,\n",
      "The me to that within heaven dispense i,\n",
      "From me or it beated look papers sharpened,\n",
      "Like set here's all insults adder's jacks that esteeming,\n",
      "For upon the all of the to fool,\n",
      "Are or course the rest swear your o makes,\n",
      "That bett'ring a thee beauty me for poor,\n",
      "Kind are anew tyrant worth lose ocean change should i,\n",
      "You more put my as which strive,\n",
      "And seeking and then and that,\n",
      "Truth the watchman nor his for use they.\n"
     ]
    }
   ],
   "source": [
    "hmm2 = unsupervised_HMM(obs, 2, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm2, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Fair hide share beauty's tongue and of will,\n",
      "Both with fear are his that,\n",
      "Of is were but what others hate thy lest with,\n",
      "In but dear thee mistress hath,\n",
      "His sweetest send thy to votary and cast,\n",
      "Long give and wand'ring still whereto to eyes cherubins,\n",
      "To gave methinks my argument side my is enmity,\n",
      "Vexed o was on i and you to,\n",
      "Thy quite eyes your to paying indeed conspire which,\n",
      "Memory thou laid impute niggard my ushers happy and,\n",
      "Particulars power and tell aspect flatter his full none,\n",
      "Heaven the sight saucy state a pattern beauties sweet hung left,\n",
      "And thee mine your buds,\n",
      "No frown this my black to this tell best.\n"
     ]
    }
   ],
   "source": [
    "hmm4 = unsupervised_HMM(obs, 4, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm4, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Like found in importune the with this waste,\n",
      "Title a as a interest beauty's sickness pent thee,\n",
      "Made by in up in my pierced in strong,\n",
      "Better burthen leaves with clouds so excellent,\n",
      "Be gainst at much so perish who of,\n",
      "See that nymphs let unfair of,\n",
      "All jacks those grief's moment yours touches work,\n",
      "Nor it think if thee for,\n",
      "That or we have thy straight is thy,\n",
      "Or and but boast my slave or,\n",
      "Bars breast both sun dead thy in fears,\n",
      "Despise the every dear-purchased decay of my,\n",
      "Dateless all the expiate sweets upon that form,\n",
      "Her appetite life that find me seal from self.\n"
     ]
    }
   ],
   "source": [
    "hmm8 = unsupervised_HMM(obs, 8, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm8, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Merits had they thought acquaintance in boast bud,\n",
      "If that them again from kind,\n",
      "And and much to fair sounds renewed from,\n",
      "Of on hast golden might their for their store,\n",
      "Morning then sing when nor respect and jaws,\n",
      "Or best use the music world is,\n",
      "Gems tables dull broke holds me it mind when suffered,\n",
      "Some why for pace than and majesty prisoner,\n",
      "My no bonds from my,\n",
      "Am see courses hath the sweet moon as,\n",
      "And and mother it there upon ill,\n",
      "Taste called live i use death's heart with fortune,\n",
      "World soil of my brave treasure and thy tears,\n",
      "Brave sweet grief untold eye to seeming why heaven lost.\n"
     ]
    }
   ],
   "source": [
    "hmm16 = unsupervised_HMM(obs, 16, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm16, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poems are all generally pretty nonsensical, but grammatically the poem with 8 hidden states and the poem with 16 hidden states performed significantly better. Since their performance grammatically was relatively similar, and both are still relatively thematically uncoordinated, for the sake of the time tradeoff we will use 8 hidden states for further generation/improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Goals:\n",
    "\n",
    "In the following preprocessing and generation functions, we modified them to attempt to include the following aspects from the actual Shakespearean poetry:\n",
    "\n",
    "#### Rhyme\n",
    "We implement the *abab cdcd efef gg* rhyme scheme by making a dictionary of all rhyming end pairs during pre-processing, and by seeding each paired phrase with a randomly generated pair from the dictionary and generating the poetry in reverse.\n",
    "\n",
    "#### Syllable Count (10)\n",
    "We implement the 10 syllable count by counting as we generate an emission and limiting the possibilities for words as we reach the end so that we end up at 10 syllables.\n",
    "\n",
    "#### Punctuation\n",
    "Since end-of-line punctuation has more to do with poetic structure than with the preceeding word, we will generate it making a distribution for each line number of what the punctuation usually is and then sampling from that distribution (with the exception of the final line, which is always a period). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we first need to parse the syllable counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_syll_text(syll_text):\n",
    "    # Convert syllable text to dictionary\n",
    "    lines = [line.split() for line in syll_text.split('\\n') if line.split()]\n",
    "\n",
    "    syll_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        word = line[0].lower()\n",
    "        syll_dict[word] = line[1:]\n",
    "\n",
    "    return syll_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of getting the words to match up, the Syllable_dictionary file was changed so that words with a leading apostrophe (i.e. 'gainst) were modified to not have the leading apostrophe, due to the way TweetTokenizer parses the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_text = open(os.path.join(os.getcwd(), 'data/Syllable_dictionary.txt')).read()\n",
    "syll_dict_text = parse_syll_text(syll_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a helper function for making the dictionary key for the rhyme_dict that returns the key and the new exception count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_key(rhyme, pair, excep):\n",
    "    common = ''\n",
    "    comm_num = 0\n",
    "    # Iterate through all the possible pronunciation combos\n",
    "    # to find which one has highest similarity (rhyme)\n",
    "    for p1 in rhyme:\n",
    "        for p2 in pair:\n",
    "            comm_test = 0\n",
    "            # Check commmon pronunciation from end onward\n",
    "            for j in range(min(len(p1), len(p2))):\n",
    "                if p1[len(p1) - j - 1] == p2[len(p2) - j - 1]:\n",
    "                    comm_test += 1\n",
    "                else:\n",
    "                    break\n",
    "            # If this pronunciation has greater commonality than \n",
    "            # any of the others, update common and comm_num\n",
    "            if comm_test > comm_num:\n",
    "                comm_num = comm_test\n",
    "                common = ' '.join(p1[len(p1) - comm_num:])\n",
    "                                        \n",
    "    # If cmudict can't find the words, we save it under the key\n",
    "    # 'excep#' instead\n",
    "    if common == '':\n",
    "        common = 'excep' + str(excep)\n",
    "        excep += 1\n",
    "    \n",
    "    return common, excep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can write our updated pre-processing function; note that sonnets 99 and 126 have irregular line numbers/rhyme schemes, so we exclude them from rhyme processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, syll_dict_text):\n",
    "    # Convert text to dataset.\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "    rhyme_dict = {}\n",
    "    syll_dict = {k: [] for k in range(6)} # Maximum syllables in shakespeare.txt is 5\n",
    "    punct_dict = {k: [] for k in range(15)}\n",
    "    \n",
    "    \n",
    "    line_num = 0\n",
    "    poem_num = 0\n",
    "    \n",
    "    a_rhyme = ()\n",
    "    b_rhyme = ()\n",
    "    excep = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is empty\n",
    "        if sentence != []:\n",
    "            # If the line is a new poem, restart the numbering\n",
    "            if sentence[0].isnumeric():\n",
    "                line_num = 0\n",
    "                poem_num = int(sentence[0])\n",
    "            else:\n",
    "                obs_elem = []\n",
    "                punct = \".',:;!?()\";\n",
    "\n",
    "                for i in range(len(sentence)):\n",
    "                    word = sentence[i]\n",
    "                    # Remove intermediate punctuation\n",
    "                    if word in punct:\n",
    "                        # If we are at the end of the line, add the\n",
    "                        # punctuation to the relevant line in punct_dict\n",
    "                        if i == len(sentence) - 1:\n",
    "                            punct_dict[line_num].append(word)\n",
    "                    else:\n",
    "                        # Turn to lowercase\n",
    "                        word = word.lower()\n",
    "                        if word not in obs_map:\n",
    "                            # Add unique words to the observations map.\n",
    "                            obs_map[word] = obs_counter\n",
    "                            obs_counter += 1\n",
    "                             # Find the list of syllable numbers for this word\n",
    "                            if word in syll_dict_text:\n",
    "                                syll_nums = syll_dict_text[word]\n",
    "                                for syll_num in syll_nums:\n",
    "                                    # Check that the syllable count isn't and ending count\n",
    "                                    # (since we know we will only use rhyme words for ending words)\n",
    "                                    if syll_num.isnumeric():\n",
    "                                        syll_dict[int(syll_num)].append(obs_map[word])\n",
    "                         \n",
    "                        # If we are in the last word of the line\n",
    "                        if i >= len(sentence) - 2 or (i == len(sentence) - 3 and sentence[i + 1] in punct):\n",
    "                            # Add the rhyming end words to the dictionary\n",
    "                            if poem_num == 126: # Irregular because aabbccddeeff\n",
    "                                if line_num % 2 == 0:\n",
    "                                    # Get the pronunciations for the first line\n",
    "                                    a_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                else:\n",
    "                                    # Get the pronunciations for the fourth line\n",
    "                                    b_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(b_rhyme[1], b_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[b_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[b_rhyme[0]], obs_map[word]])\n",
    "                        \n",
    "                            elif not poem_num == 99: # Excluded because ababa cdcd efef gg\n",
    "                                # Since the quatrains all have the same abab structure, we can\n",
    "                                # parse modulo 4\n",
    "                                if line_num % 4 == 0:\n",
    "                                    # Get the pronunciations for the first line\n",
    "                                    a_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 1 and not line_num == 13:\n",
    "                                    # Get the pronunciations for the second line\n",
    "                                    b_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 2 or line_num == 13:\n",
    "                                    # Get the pronunciations for the third line/last line\n",
    "                                    a_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(a_rhyme[1], a_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[a_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[a_rhyme[0]], obs_map[word]])\n",
    "                                else:\n",
    "                                    # Get the pronunciations for the fourth line\n",
    "                                    b_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(b_rhyme[1], b_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[b_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[b_rhyme[0]], obs_map[word]])\n",
    "                        \n",
    "                        # Add the encoded word.\n",
    "                        obs_elem.append(obs_map[word])\n",
    "\n",
    "                # Add the encoded sequence.\n",
    "                obs.append(obs_elem)\n",
    "                \n",
    "                # Increment the line numbering\n",
    "                line_num += 1\n",
    "\n",
    "    return obs, obs_map, rhyme_dict, syll_dict, punct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map, rhyme_dict, syll_dict, punct_dict = preprocess(text, syll_dict_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since rhyme_dict has duplicates, we go through and use np.unique to eliminate them for better processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scheme in rhyme_dict:\n",
    "    rhyme_dict[scheme] = np.unique(rhyme_dict[scheme])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to modify the emission and poetry generation functions to utilize our rhyme, syllable, and punctuation data.\n",
    "\n",
    "#### Emission:\n",
    "We are now seeding each phrase with our given rhyming word, so we now select our start state as the one that has the highest probability of generating that word. \n",
    "\n",
    "#### Generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the obs_map, we also need to generate a backwards dictionary for the syllables so we can count for emissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_syll(obs_map, syll_dict_text):\n",
    "    o2s_dict = {}\n",
    "    for word in syll_dict_text:\n",
    "        nums = []\n",
    "        for num in syll_dict_text[word]:\n",
    "            # We can exclude ending syllables because once again, we do not use them for \n",
    "            # generating emissions because we always seed with the last word\n",
    "            if num.isnumeric():\n",
    "                nums.append(int(num))\n",
    "        if word in obs_map:\n",
    "            o2s_dict[obs_map[word]] = nums\n",
    "    \n",
    "    return o2s_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2s_dict = obs_to_syll(obs_map, syll_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
