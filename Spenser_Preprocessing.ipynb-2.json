{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Spenser Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'backward' from 'HMM_Project3' (/Users/mayamutic/HMM_Project3.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-8bec331a5f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcmudict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mHMM_Project3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtknzr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'backward' from 'HMM_Project3' (/Users/mayamutic/HMM_Project3.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from HMM_Project3 import unsupervised_HMM\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main difference between the Shakespeare and Spenser sonnets are the way they are numbered in the text file. Spenser sonnets are marked with roman numerals, which are registered as letters, so to eliminate them from the data, we check if each non empty line has fewer than 10 characters. If this is the case, then it must be a roman numeral as all other lines clearly have more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_init(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is poem numbering (roman numerals)\n",
    "        if sentence != [] and len(line)>10: \n",
    "            obs_elem = []\n",
    "            punct = \".',':;!?()\"; \n",
    "            \n",
    "            for word in sentence:\n",
    "                # Remove intermediate punctuation\n",
    "                if not word in punct:\n",
    "                    # Turn to lowercase\n",
    "                    word = word.lower()\n",
    "                    if word not in obs_map:\n",
    "                        # Add unique words to the observations map.\n",
    "                        obs_map[word] = obs_counter\n",
    "                        obs_counter += 1\n",
    "\n",
    "                    # Add the encoded word.\n",
    "                    obs_elem.append(obs_map[word])\n",
    "\n",
    "            # Add the encoded sequence.\n",
    "            obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'spenser.txt')).read()\n",
    "obs, obs_map = preprocess_init(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of all spenser line lengths (in terms of number of words)\n",
    "line_lens = [len(i) for i in obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_init(hmm, obs_map, line_lens):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    for i in range(14):\n",
    "        # Get desired line length:\n",
    "        n_words = random.choice(line_lens)\n",
    "        emission, states = hmm.generate_emission(n_words)\n",
    "        sentence = [obs_map_r[i] for i in emission]\n",
    "        \n",
    "        formatted = ' '.join(sentence).capitalize()\n",
    "        if i < 13:\n",
    "            formatted += \",\\n\"\n",
    "        else:\n",
    "            formatted += \".\"\n",
    "        \n",
    "        poem += formatted\n",
    "\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing done on shakespeare sonnets determined that 8 states was optimal, which is what we use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'HMM_Project3' has no attribute 'unsupervised_HMM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-38bdaeb6a955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhmm8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHMM_Project3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsupervised_HMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nSample Poem:\\n===================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_poem_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'HMM_Project3' has no attribute 'unsupervised_HMM'"
     ]
    }
   ],
   "source": [
    "\n",
    "hmm8 = HMM_Project3.unsupervised_HMM(obs, 8, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm8, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
