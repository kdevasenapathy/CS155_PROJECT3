{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Spenser Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from HMM_Project3 import unsupervised_HMM\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main difference between the Shakespeare and Spenser sonnets are the way they are numbered in the text file. Spenser sonnets are marked with roman numerals, which are registered as letters, so to eliminate them from the data, we check if each non empty line has fewer than 10 characters. If this is the case, then it must be a roman numeral as all other lines clearly have more characters. We combined the sonnet files by reading both of them into the preprocessing function and making them into one list of lines in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_init(text1, text2):\n",
    "    # Convert text to dataset.\n",
    "    lines1 = text1.split('\\n')\n",
    "    lines2 = text2.split('\\n')\n",
    "    lines = lines1 + lines2\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is poem numbering (roman numerals or regular numbers)\n",
    "        if sentence != [] and len(line)>10: \n",
    "            obs_elem = []\n",
    "            punct = \".',':;!?()\"; \n",
    "            \n",
    "            for word in sentence:\n",
    "                # Remove intermediate punctuation\n",
    "                if not word in punct:\n",
    "                    # Turn to lowercase\n",
    "                    word = word.lower()\n",
    "                    if word not in obs_map:\n",
    "                        # Add unique words to the observations map.\n",
    "                        obs_map[word] = obs_counter\n",
    "                        obs_counter += 1\n",
    "\n",
    "                    # Add the encoded word.\n",
    "                    obs_elem.append(obs_map[word])\n",
    "\n",
    "            # Add the encoded sequence.\n",
    "            obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "text2 = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map = preprocess_init(text1, text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of all spenser line lengths (in terms of number of words)\n",
    "line_lens = [len(i) for i in obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_init(hmm, obs_map, line_lens):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    for i in range(14):\n",
    "        # Get desired line length:\n",
    "        n_words = random.choice(line_lens)\n",
    "        emission, states = hmm.generate_emission(n_words)\n",
    "        sentence = [obs_map_r[i] for i in emission]\n",
    "        \n",
    "        formatted = ' '.join(sentence).capitalize()\n",
    "        if i < 13:\n",
    "            formatted += \",\\n\"\n",
    "        else:\n",
    "            formatted += \".\"\n",
    "        \n",
    "        poem += formatted\n",
    "\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing done on shakespeare sonnets determined that 8 states was optimal, which is what we use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n",
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Your so converted in quite not planet register,\n",
      "This you comfort him away lord shaken slow write in,\n",
      "Away what of kindle making trespass growing thy,\n",
      "Bit lovers for with my for lest thine,\n",
      "Sunset to any and and battle,\n",
      "Life t'adorn that fairest is she do that dear my,\n",
      "I leads them and to what to find,\n",
      "Light to grow doom unto thine most of sad,\n",
      "She others my your thing and seek may,\n",
      "Dost more with thereof of that back were for,\n",
      "The sweetest how come i that souls that to,\n",
      "To warrior servant and but time's dear,\n",
      "Thence where and doth immortalize no tell him,\n",
      "This which hounds heart leaped the me them take.\n"
     ]
    }
   ],
   "source": [
    "hmm8 = unsupervised_HMM(obs, 8, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm8, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_syll_text(syll_text):\n",
    "    # Convert syllable text to dictionary\n",
    "    lines = [line.split() for line in syll_text.split('\\n') if line.split()]\n",
    "\n",
    "    syll_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        word = line[0].lower()\n",
    "        syll_dict[word] = line[1:]\n",
    "\n",
    "    return syll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_text = open(os.path.join(os.getcwd(), 'data/Syllable_dictionary.txt')).read()\n",
    "syll_dict_text = parse_syll_text(syll_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_key(rhyme, pair, excep):\n",
    "    common = ''\n",
    "    comm_num = 0\n",
    "    # Iterate through all the possible pronunciation combos\n",
    "    # to find which one has highest similarity (rhyme)\n",
    "    for p1 in rhyme:\n",
    "        for p2 in pair:\n",
    "            comm_test = 0\n",
    "            # Check commmon pronunciation from end onward\n",
    "            for j in range(min(len(p1), len(p2))):\n",
    "                if p1[len(p1) - j - 1] == p2[len(p2) - j - 1]:\n",
    "                    comm_test += 1\n",
    "                else:\n",
    "                    break\n",
    "            # If this pronunciation has greater commonality than \n",
    "            # any of the others, update common and comm_num\n",
    "            if comm_test > comm_num:\n",
    "                comm_num = comm_test\n",
    "                common = ' '.join(p1[len(p1) - comm_num:])\n",
    "                                        \n",
    "    # If cmudict can't find the words, we save it under the key\n",
    "    # 'excep#' instead\n",
    "    if common == '':\n",
    "        common = 'excep' + str(excep)\n",
    "        excep += 1\n",
    "    \n",
    "    return common, excep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text1, text2, syll_dict_text):\n",
    "    # Convert text to dataset.\n",
    "    lines1 = text1.split('\\n')\n",
    "    lines2 = text2.split('\\n')\n",
    "    lines = lines1 + lines2\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "    rhyme_dict = {}\n",
    "    syll_dict = {k: [] for k in range(6)} # Maximum syllables in shakespeare.txt is 5\n",
    "    punct_dict = {k: [] for k in range(15)}\n",
    "    \n",
    "    \n",
    "    line_num = 0\n",
    "    poem_num = \"\"\n",
    "    \n",
    "    a_rhyme = ()\n",
    "    b_rhyme = ()\n",
    "    excep = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is empty\n",
    "        if sentence != []:\n",
    "            # If the line is a new poem, restart the numbering\n",
    "            if len(line)<=10 or sentence[0].isnumeric():\n",
    "                line_num = 0\n",
    "                poem_num = sentence[0]\n",
    "            else:\n",
    "                obs_elem = []\n",
    "                punct = \".',:;!?()\";\n",
    "\n",
    "                for i in range(len(sentence)):\n",
    "                    word = sentence[i]\n",
    "                    # Remove intermediate punctuation\n",
    "                    if word in punct:\n",
    "                        # If we are at the end of the line, add the\n",
    "                        # punctuation to the relevant line in punct_dict\n",
    "                        if i == len(sentence) - 1:\n",
    "                            punct_dict[line_num].append(word)\n",
    "                    else:\n",
    "                        # Turn to lowercase\n",
    "                        word = word.lower()\n",
    "                        if word not in obs_map:\n",
    "                            # Add unique words to the observations map.\n",
    "                            obs_map[word] = obs_counter\n",
    "                            obs_counter += 1\n",
    "                             # Find the list of syllable numbers for this word\n",
    "                            if word in syll_dict_text:\n",
    "                                syll_nums = syll_dict_text[word]\n",
    "                                for syll_num in syll_nums:\n",
    "                                    # Check that the syllable count isn't and ending count\n",
    "                                    # (since we know we will only use rhyme words for ending words)\n",
    "                                    if syll_num.isnumeric():\n",
    "                                        syll_dict[int(syll_num)].append(obs_map[word])\n",
    "                         \n",
    "                        # If we are in the last word of the line\n",
    "                        if i >= len(sentence) - 2 or (i == len(sentence) - 3 and sentence[i + 1] in punct):\n",
    "                            # Add the rhyming end words to the dictionary\n",
    "                            # Since the quatrains all have the same abab structure, we can\n",
    "                            # parse modulo 4\n",
    "                            if poem_num != \"LXXXIV\" and not poem_num == 99 and not poem_num == 126:\n",
    "                                if line_num % 4 == 0:\n",
    "                                    # Get the pronunciations for the first line\n",
    "                                    a_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 1 and not line_num == 13:\n",
    "                                    # Get the pronunciations for the second line\n",
    "                                    b_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 2 or line_num == 13:\n",
    "                                    # Get the pronunciations for the third line/last line\n",
    "                                    a_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(a_rhyme[1], a_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[a_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[a_rhyme[0]], obs_map[word]])\n",
    "                                else:\n",
    "                                    # Get the pronunciations for the fourth line\n",
    "                                    b_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(b_rhyme[1], b_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[b_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[b_rhyme[0]], obs_map[word]])\n",
    "\n",
    "                        # Add the encoded word.\n",
    "                        obs_elem.append(obs_map[word])\n",
    "\n",
    "                # Add the encoded sequence.\n",
    "                obs.append(obs_elem)\n",
    "                \n",
    "                # Increment the line numbering\n",
    "                line_num += 1\n",
    "\n",
    "    return obs, obs_map, rhyme_dict, syll_dict, punct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "text2 = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "obs, obs_map, rhyme_dict, syll_dict, punct_dict = preprocess(text1, text2, syll_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scheme in rhyme_dict:\n",
    "    rhyme_dict[scheme] = np.unique(rhyme_dict[scheme])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_syll(obs_map, syll_dict_text):\n",
    "    o2s_dict = {}\n",
    "    for word in syll_dict_text:\n",
    "        nums = []\n",
    "        for num in syll_dict_text[word]:\n",
    "            # We can exclude ending syllables because once again, we do not use them for \n",
    "            # generating emissions because we always seed with the last word\n",
    "            if num.isnumeric():\n",
    "                nums.append(int(num))\n",
    "        if word in obs_map:\n",
    "            o2s_dict[obs_map[word]] = nums\n",
    "    \n",
    "    return o2s_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2s_dict = obs_to_syll(obs_map, syll_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_improved(hmm, syll_count, seed, syll_dict, o2s_dict):\n",
    "        emission = [seed]\n",
    "        state = np.argmax(np.array(hmm.O)[:, seed])\n",
    "        states = []\n",
    "\n",
    "        while syll_count < 10:\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "\n",
    "            # At this point, we start restricting the probabilities\n",
    "            if syll_count >= 5:\n",
    "                accept_obs = []\n",
    "\n",
    "                # Get a list of all the observations with \n",
    "                # acceptable syllable counts\n",
    "                for syll_num in syll_dict:\n",
    "                    if syll_num <= 10 - syll_count:\n",
    "                        accept_obs.extend(syll_dict[syll_num])\n",
    "\n",
    "                accept_obs = np.unique(accept_obs)\n",
    "                # Get the total probability for the given state\n",
    "                # across all of these acceptable observations\n",
    "                O_tot = np.sum([hmm.O[state][i] for i in accept_obs])\n",
    "\n",
    "                # Sample next observation.\n",
    "                rand_var = random.uniform(0, O_tot)\n",
    "\n",
    "                for i in range(len(accept_obs)):\n",
    "                    rand_var -= hmm.O[state][accept_obs[i]]\n",
    "                    if rand_var <= 0:\n",
    "                        break\n",
    "\n",
    "                next_obs = accept_obs[i - 1]\n",
    "            else:\n",
    "                 # Sample next observation.\n",
    "                rand_var = random.uniform(0, 1)\n",
    "                next_obs = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= hmm.O[state][next_obs]\n",
    "                    next_obs += 1\n",
    "\n",
    "                next_obs -= 1\n",
    "\n",
    "            emission.append(next_obs)\n",
    "\n",
    "            # Increase the syllable count (using max possible, since\n",
    "            # Shakespeare says brevity is the soul of wit)\n",
    "            if next_obs in o2s_dict:\n",
    "                pos_counts = o2s_dict[next_obs]\n",
    "            else:\n",
    "                pos_counts = [2]\n",
    "            for i in range(len(pos_counts)):\n",
    "                if pos_counts[len(pos_counts) - i - 1] <= 10 - syll_count:\n",
    "                    syll_count += pos_counts[len(pos_counts) - i - 1]\n",
    "                    break\n",
    "\n",
    "            # Sample next state.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_state = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= hmm.A[state][next_state]\n",
    "                next_state += 1\n",
    "\n",
    "            next_state -= 1\n",
    "            state = next_state\n",
    "\n",
    "        return emission, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rhyming schemes for Spenser sonnets are similar to Shakespeare, but technically follow the scheme \"ababbcbccdcdee\" instead of \"ababcdcdefefgg.\" For simplicity, we chose to follow Shakespeare's rhyme scheme as both schemes have every other line rhyme (except for the couplet at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(hmm, obs_map, rhyme_dict, syll_dict, punct_dict, syll_dict_text, o2s_dict):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = ['' for i in range(14)]\n",
    "    # Tracks the beginnings of coupled lines\n",
    "    line_nums = [0, 1, 4, 5, 8, 9]\n",
    "    \n",
    "    # Each loop generates a couplet, which we will intersperse into the desired rhyme scheme\n",
    "    for i in range(7):\n",
    "        # Get random rhyme scheme\n",
    "        scheme = random.sample(rhyme_dict.keys(), 1)\n",
    "        \n",
    "        # Get two ending words\n",
    "        rhymes = random.sample(list(rhyme_dict[scheme[0]]), 2)\n",
    "        \n",
    "        # Get the syllable count for each ending word (check the E)\n",
    "        syll_count = []\n",
    "        for word in rhymes:\n",
    "            word_syll = 0\n",
    "            if obs_map_r[word] in syll_dict_text:\n",
    "                for pos_count in syll_dict_text[obs_map_r[word]]:\n",
    "                    if 'E' in pos_count:\n",
    "                        word_syll = int(pos_count[1])\n",
    "                        break\n",
    "                    else:\n",
    "                        word_syll = int(pos_count)\n",
    "            else:\n",
    "                word_syll = 2\n",
    "            syll_count.append(word_syll)\n",
    "        \n",
    "        # Generate the two rhyming sentences\n",
    "        sentence = []\n",
    "        for j in range(2):\n",
    "            emission, states = generate_emission_improved(hmm, syll_count[j], rhymes[j], syll_dict, o2s_dict)\n",
    "            # Reverse the order of the sentence (since our rhyming words should be at the end)\n",
    "            emission = emission[::-1]\n",
    "            sentence.append([obs_map_r[k] for k in emission])\n",
    "        \n",
    "        \n",
    "        # Now that we have our two sentences, we use our index i value to put them into the poem\n",
    "        # with the appropriate punctuation\n",
    "        # If we have reached the couplet, i = 6:\n",
    "        if i == 6:\n",
    "            punct = random.sample(punct_dict[12], 1)\n",
    "            poem[12] = (' '.join(sentence[0]).capitalize()) + punct[0]\n",
    "            poem[13] = \"  \" + (' '.join(sentence[1]).capitalize()) + \".\"\n",
    "        elif i in [0, 2, 4]:\n",
    "            first = line_nums[i]\n",
    "            punct_first = random.sample(punct_dict[first], 1)\n",
    "            punct_sec = random.sample(punct_dict[first + 2], 1)\n",
    "            poem[first] = (' '.join(sentence[0]).capitalize()) + punct_first[0]\n",
    "            poem[first + 2] = \"  \" + (' '.join(sentence[1]).capitalize()) + punct_sec[0]\n",
    "        else:\n",
    "            first = line_nums[i]\n",
    "            punct_first = random.sample(punct_dict[first], 1)\n",
    "            punct_sec = random.sample(punct_dict[first + 2], 1)\n",
    "            poem[first] = \"  \" + (' '.join(sentence[0]).capitalize()) + punct_first[0]\n",
    "            poem[first + 2] = \"  \" + (' '.join(sentence[1]).capitalize()) + punct_sec[0]\n",
    "        \n",
    "    poem_formatted = \"\\n\".join(poem)\n",
    "\n",
    "    return poem_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n"
     ]
    }
   ],
   "source": [
    "hmm8 = unsupervised_HMM(obs, 8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n",
      "Is you delight blossomed eclipse meeds,\n",
      "  Coward sometimes any angel enough?\n",
      "  At eyes remain life whether you more deeds,\n",
      "  That's looks on live know the in what tough.\n",
      "Tame bears do some forty most re-survey)\n",
      "  Will happy bids tongue which a thing bath faces?\n",
      "  Sorrows grant hell dilate of wherefore day:\n",
      "  Inward on worthy shames thy i oaths graces.\n",
      "Complain kiss longer tomb with inward grows,\n",
      "  She shall tyranny of long him awhile,\n",
      "  Stand you sovereign if eyes they seas but,\n",
      "  You an both feeds hold thou mercy mile:\n",
      "Greater devised becomes depending proud their o'er,\n",
      "  Greater expire on earth these could before.\n"
     ]
    }
   ],
   "source": [
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem(hmm8, obs_map, rhyme_dict, syll_dict, punct_dict, syll_dict_text, o2s_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
