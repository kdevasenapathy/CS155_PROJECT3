{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Spenser Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'unsupervised_HMM' from 'HMM_Project3' (/Users/mayamutic/HMM_Project3.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-ac22f3f4a004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcmudict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mHMM_Project3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munsupervised_HMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtknzr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'unsupervised_HMM' from 'HMM_Project3' (/Users/mayamutic/HMM_Project3.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from HMM_Project3 import unsupervised_HMM\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The main difference between the Shakespeare and Spenser sonnets are the way they are numbered in the text file. Spenser sonnets are marked with roman numerals, which are registered as letters, so to eliminate them from the data, we check if each non empty line has fewer than 10 characters. If this is the case, then it must be a roman numeral as all other lines clearly have more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_init(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is poem numbering (roman numerals)\n",
    "        if sentence != [] and len(line)>10: \n",
    "            obs_elem = []\n",
    "            punct = \".',':;!?()\"; \n",
    "            \n",
    "            for word in sentence:\n",
    "                # Remove intermediate punctuation\n",
    "                if not word in punct:\n",
    "                    # Turn to lowercase\n",
    "                    word = word.lower()\n",
    "                    if word not in obs_map:\n",
    "                        # Add unique words to the observations map.\n",
    "                        obs_map[word] = obs_counter\n",
    "                        obs_counter += 1\n",
    "\n",
    "                    # Add the encoded word.\n",
    "                    obs_elem.append(obs_map[word])\n",
    "\n",
    "            # Add the encoded sequence.\n",
    "            obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mayamutic/data/spenser.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-983372ab44cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/spenser.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mayamutic/data/spenser.txt'"
     ]
    }
   ],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/spenser.txt')).read()\n",
    "obs, obs_map = preprocess_init(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate array of all spenser line lengths (in terms of number of words)\n",
    "line_lens = [len(i) for i in obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem_init(hmm, obs_map, line_lens):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = \"\"\n",
    "    \n",
    "    for i in range(14):\n",
    "        # Get desired line length:\n",
    "        n_words = random.choice(line_lens)\n",
    "        emission, states = hmm.generate_emission(n_words)\n",
    "        sentence = [obs_map_r[i] for i in emission]\n",
    "        \n",
    "        formatted = ' '.join(sentence).capitalize()\n",
    "        if i < 13:\n",
    "            formatted += \",\\n\"\n",
    "        else:\n",
    "            formatted += \".\"\n",
    "        \n",
    "        poem += formatted\n",
    "\n",
    "    return poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Preprocessing done on shakespeare sonnets determined that 8 states was optimal, which is what we use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'HMM_Project3' has no attribute 'unsupervised_HMM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-38bdaeb6a955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhmm8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHMM_Project3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsupervised_HMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nSample Poem:\\n===================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_poem_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'HMM_Project3' has no attribute 'unsupervised_HMM'"
     ]
    }
   ],
   "source": [
    "hmm8 = HMM_Project3.unsupervised_HMM(obs, 8, 100)\n",
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem_init(hmm8, obs_map, line_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_syll_text(syll_text):\n",
    "    # Convert syllable text to dictionary\n",
    "    lines = [line.split() for line in syll_text.split('\\n') if line.split()]\n",
    "\n",
    "    syll_dict = {}\n",
    "\n",
    "    for line in lines:\n",
    "        word = line[0].lower()\n",
    "        syll_dict[word] = line[1:]\n",
    "\n",
    "    return syll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_text = open(os.path.join(os.getcwd(), 'data/Syllable_dictionary.txt')).read()\n",
    "syll_dict_text = parse_syll_text(syll_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme_key(rhyme, pair, excep):\n",
    "    common = ''\n",
    "    comm_num = 0\n",
    "    # Iterate through all the possible pronunciation combos\n",
    "    # to find which one has highest similarity (rhyme)\n",
    "    for p1 in rhyme:\n",
    "        for p2 in pair:\n",
    "            comm_test = 0\n",
    "            # Check commmon pronunciation from end onward\n",
    "            for j in range(min(len(p1), len(p2))):\n",
    "                if p1[len(p1) - j - 1] == p2[len(p2) - j - 1]:\n",
    "                    comm_test += 1\n",
    "                else:\n",
    "                    break\n",
    "            # If this pronunciation has greater commonality than \n",
    "            # any of the others, update common and comm_num\n",
    "            if comm_test > comm_num:\n",
    "                comm_num = comm_test\n",
    "                common = ' '.join(p1[len(p1) - comm_num:])\n",
    "                                        \n",
    "    # If cmudict can't find the words, we save it under the key\n",
    "    # 'excep#' instead\n",
    "    if common == '':\n",
    "        common = 'excep' + str(excep)\n",
    "        excep += 1\n",
    "    \n",
    "    return common, excep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, syll_dict_text):\n",
    "    # Convert text to dataset.\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "    rhyme_dict = {}\n",
    "    syll_dict = {k: [] for k in range(6)} # Maximum syllables in shakespeare.txt is 5\n",
    "    punct_dict = {k: [] for k in range(15)}\n",
    "    \n",
    "    \n",
    "    line_num = 0\n",
    "    poem_num = \"\"\n",
    "    \n",
    "    a_rhyme = ()\n",
    "    b_rhyme = ()\n",
    "    excep = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # Separate into words using TweetTokenizer and lowercase\n",
    "        sentence = tknzr.tokenize(line)\n",
    "        # Skip if line is empty\n",
    "        if sentence != []:\n",
    "            # If the line is a new poem, restart the numbering\n",
    "            if len(line)<=10:\n",
    "                line_num = 0\n",
    "                poem_num = line\n",
    "            else:\n",
    "                obs_elem = []\n",
    "                punct = \".',:;!?()\";\n",
    "\n",
    "                for i in range(len(sentence)):\n",
    "                    word = sentence[i]\n",
    "                    # Remove intermediate punctuation\n",
    "                    if word in punct:\n",
    "                        # If we are at the end of the line, add the\n",
    "                        # punctuation to the relevant line in punct_dict\n",
    "                        if i == len(sentence) - 1:\n",
    "                            punct_dict[line_num].append(word)\n",
    "                    else:\n",
    "                        # Turn to lowercase\n",
    "                        word = word.lower()\n",
    "                        if word not in obs_map:\n",
    "                            # Add unique words to the observations map.\n",
    "                            obs_map[word] = obs_counter\n",
    "                            obs_counter += 1\n",
    "                             # Find the list of syllable numbers for this word\n",
    "                            if word in syll_dict_text:\n",
    "                                syll_nums = syll_dict_text[word]\n",
    "                                for syll_num in syll_nums:\n",
    "                                    # Check that the syllable count isn't and ending count\n",
    "                                    # (since we know we will only use rhyme words for ending words)\n",
    "                                    if syll_num.isnumeric():\n",
    "                                        syll_dict[int(syll_num)].append(obs_map[word])\n",
    "                         \n",
    "                        # If we are in the last word of the line\n",
    "                        if i >= len(sentence) - 2 or (i == len(sentence) - 3 and sentence[i + 1] in punct):\n",
    "                            # Add the rhyming end words to the dictionary\n",
    "                            # Since the quatrains all have the same abab structure, we can\n",
    "                            # parse modulo 4\n",
    "                            if poem_num != \"LXXXIV\":\n",
    "                                if line_num % 4 == 0:\n",
    "                                    # Get the pronunciations for the first line\n",
    "                                    a_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 1 and not line_num == 13:\n",
    "                                    # Get the pronunciations for the second line\n",
    "                                    b_rhyme = (word, [p for (w, p) in cmudict.entries() if w == word])\n",
    "                                elif line_num % 4 == 2 or line_num == 13:\n",
    "                                    # Get the pronunciations for the third line/last line\n",
    "                                    a_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(a_rhyme[1], a_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[a_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[a_rhyme[0]], obs_map[word]])\n",
    "                                else:\n",
    "                                    # Get the pronunciations for the fourth line\n",
    "                                    b_pair = [p for (w, p) in cmudict.entries() if w == word]\n",
    "                                    common, excep = get_rhyme_key(b_rhyme[1], b_pair, excep)\n",
    "\n",
    "                                    # Add the words to the dictionary\n",
    "                                    if common not in rhyme_dict:\n",
    "                                        # Add unique rhyme schemes to the rhyme dict\n",
    "                                        rhyme_dict[common] = [obs_map[b_rhyme[0]], obs_map[word]]\n",
    "                                    else:\n",
    "                                        rhyme_dict[common].extend([obs_map[b_rhyme[0]], obs_map[word]])\n",
    "\n",
    "                        # Add the encoded word.\n",
    "                        obs_elem.append(obs_map[word])\n",
    "\n",
    "                # Add the encoded sequence.\n",
    "                obs.append(obs_elem)\n",
    "                \n",
    "                # Increment the line numbering\n",
    "                line_num += 1\n",
    "\n",
    "    return obs, obs_map, rhyme_dict, syll_dict, punct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'spenser.txt')).read()\n",
    "obs, obs_map, rhyme_dict, syll_dict, punct_dict = preprocess(text, syll_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rhyme_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-3864e4aa56db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrhyme_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrhyme_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhyme_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rhyme_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for scheme in rhyme_dict:\n",
    "    rhyme_dict[scheme] = np.unique(rhyme_dict[scheme])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_syll(obs_map, syll_dict_text):\n",
    "    o2s_dict = {}\n",
    "    for word in syll_dict_text:\n",
    "        nums = []\n",
    "        for num in syll_dict_text[word]:\n",
    "            # We can exclude ending syllables because once again, we do not use them for \n",
    "            # generating emissions because we always seed with the last word\n",
    "            if num.isnumeric():\n",
    "                nums.append(int(num))\n",
    "        if word in obs_map:\n",
    "            o2s_dict[obs_map[word]] = nums\n",
    "    \n",
    "    return o2s_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2s_dict = obs_to_syll(obs_map, syll_dict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emission_improved(hmm, syll_count, seed, syll_dict, o2s_dict):\n",
    "        emission = [seed]\n",
    "        state = np.argmax(np.array(hmm.O)[:, seed])\n",
    "        states = []\n",
    "\n",
    "        while syll_count < 10:\n",
    "            # Append state.\n",
    "            states.append(state)\n",
    "\n",
    "            # At this point, we start restricting the probabilities\n",
    "            if syll_count >= 5:\n",
    "                accept_obs = []\n",
    "\n",
    "                # Get a list of all the observations with \n",
    "                # acceptable syllable counts\n",
    "                for syll_num in syll_dict:\n",
    "                    if syll_num <= 10 - syll_count:\n",
    "                        accept_obs.extend(syll_dict[syll_num])\n",
    "\n",
    "                accept_obs = np.unique(accept_obs)\n",
    "                # Get the total probability for the given state\n",
    "                # across all of these acceptable observations\n",
    "                O_tot = np.sum([hmm.O[state][i] for i in accept_obs])\n",
    "\n",
    "                # Sample next observation.\n",
    "                rand_var = random.uniform(0, O_tot)\n",
    "\n",
    "                for i in range(len(accept_obs)):\n",
    "                    rand_var -= hmm.O[state][accept_obs[i]]\n",
    "                    if rand_var <= 0:\n",
    "                        break\n",
    "\n",
    "                next_obs = accept_obs[i - 1]\n",
    "            else:\n",
    "                 # Sample next observation.\n",
    "                rand_var = random.uniform(0, 1)\n",
    "                next_obs = 0\n",
    "\n",
    "                while rand_var > 0:\n",
    "                    rand_var -= hmm.O[state][next_obs]\n",
    "                    next_obs += 1\n",
    "\n",
    "                next_obs -= 1\n",
    "\n",
    "            emission.append(next_obs)\n",
    "\n",
    "            # Increase the syllable count (using max possible, since\n",
    "            # Shakespeare says brevity is the soul of wit)\n",
    "            pos_counts = o2s_dict[next_obs]\n",
    "            for i in range(len(pos_counts)):\n",
    "                if pos_counts[len(pos_counts) - i - 1] <= 10 - syll_count:\n",
    "                    syll_count += pos_counts[len(pos_counts) - i - 1]\n",
    "                    break\n",
    "\n",
    "            # Sample next state.\n",
    "            rand_var = random.uniform(0, 1)\n",
    "            next_state = 0\n",
    "\n",
    "            while rand_var > 0:\n",
    "                rand_var -= hmm.A[state][next_state]\n",
    "                next_state += 1\n",
    "\n",
    "            next_state -= 1\n",
    "            state = next_state\n",
    "\n",
    "        return emission, states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rhyming schemes for Spenser sonnets are similar to Shakespeare, but technically follow the scheme \"ababbcbccdcdee\" instead of \"ababcdcdefefgg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(hmm, obs_map, rhyme_dict, syll_dict, punct_dict, syll_dict_text, o2s_dict):\n",
    "    # Get reverse map.\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    \n",
    "    poem = ['' for i in range(14)]\n",
    "    # Tracks the beginnings of coupled lines\n",
    "    line_nums = [0, 1, 4, 5, 8, 9]\n",
    "    \n",
    "    # Each loop generates a couplet, which we will intersperse into the desired rhyme scheme\n",
    "    for i in range(5):\n",
    "        # Get random rhyme scheme\n",
    "        scheme = random.sample(rhyme_dict.keys(), 1)\n",
    "        \n",
    "        # Get four ending words\n",
    "        rhymes = random.sample(list(rhyme_dict[scheme[0]]), 4)\n",
    "        \n",
    "        # Get the syllable count for each ending word (check the E)\n",
    "        syll_count = []\n",
    "        for word in rhymes:\n",
    "            word_syll = 0\n",
    "            for pos_count in syll_dict_text[obs_map_r[word]]:\n",
    "                if 'E' in pos_count:\n",
    "                    word_syll = int(pos_count[1])\n",
    "                    break\n",
    "                else:\n",
    "                    word_syll = int(pos_count)\n",
    "            syll_count.append(word_syll)\n",
    "        \n",
    "        # Generate the two rhyming sentences\n",
    "        sentence = []\n",
    "        for j in range(4):\n",
    "            emission, states = generate_emission_improved(hmm, syll_count[j], rhymes[j], syll_dict, o2s_dict)\n",
    "            # Reverse the order of the sentence (since our rhyming words should be at the end)\n",
    "            emission = emission[::-1]\n",
    "            sentence.append([obs_map_r[k] for k in emission])\n",
    "        \n",
    "        \n",
    "        # Now that we have our four sentences, we use our index i value to put them into the poem\n",
    "        # with the appropriate punctuation. Since some words are only rhymed twice, we won't end\n",
    "        # up using all of the generated sentences\n",
    "        # If we have reached the couplet, i = 4:\n",
    "        # ababbcbccdcdee\n",
    "        if i == 4:\n",
    "            punct = random.sample(punct_dict[12], 1)\n",
    "            poem[12] = (' '.join(sentence[0]).capitalize()) + punct[0]\n",
    "            poem[13] = \"  \" + (' '.join(sentence[1]).capitalize()) + \".\"\n",
    "        elif i == 0:\n",
    "            first = line_nums[i]\n",
    "            punct_first = random.sample(punct_dict[first], 1)\n",
    "            punct_sec = random.sample(punct_dict[first + 2], 1)\n",
    "            poem[first] = (' '.join(sentence[0]).capitalize()) + punct_first[0]\n",
    "            poem[first + 2] = \"  \" + (' '.join(sentence[1]).capitalize()) + punct_sec[0]\n",
    "        elif i == 3:\n",
    "            first = line_nums[i]\n",
    "            punct_first = random.sample(punct_dict[first], 1)\n",
    "            poem[first] = \"  \" + (' '.join(sentence[0]).capitalize()) + punct_first[0]\n",
    "            poem[first + 2] = \"  \" + (' '.join(sentence[1]).capitalize()) + \".\"\n",
    "        elif i == 1 or i == 2:\n",
    "            first = line_nums[i]\n",
    "            punct_first = random.sample(punct_dict[first],1)\n",
    "            punct_third = random.sample(punct_dict[first + 3],1)\n",
    "            punct_fourth = random.sample(punct_dict[first + 5],1)\n",
    "            poem[first] = \"  \" + (' '.join(sentence[0].capitalize()) + punct_first[0])\n",
    "            poem[first + 2] = \"  \" + (' '.join(sentence[1].capitalize())) + \".\"\n",
    "            poem[first + 3] = (' '.join(sentence[2].capitalize()) + punct_third[0])\n",
    "            poem[first + 5] = \"  \" + (' '.join(sentence[3].capitalize()) + punct_fourth[0])\n",
    "        \n",
    "    poem_formatted = \"\\n\".join(poem)\n",
    "\n",
    "    return poem_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unsupervised_HMM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-f02a3aab9b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhmm8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsupervised_HMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'unsupervised_HMM' is not defined"
     ]
    }
   ],
   "source": [
    "hmm8 = unsupervised_HMM(obs, 8, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Poem:\n",
      "====================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hmm8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-81ee29d3ae6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nSample Poem:\\n===================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_poem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhyme_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyll_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpunct_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyll_dict_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2s_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hmm8' is not defined"
     ]
    }
   ],
   "source": [
    "print('\\nSample Poem:\\n====================')\n",
    "print(generate_poem(hmm8, obs_map, rhyme_dict, syll_dict, punct_dict, syll_dict_text, o2s_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
